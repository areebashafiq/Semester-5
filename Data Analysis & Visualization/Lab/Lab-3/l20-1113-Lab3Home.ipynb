{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abdul Saboor (20L-1113 | BDS-5A1)\n",
    "\n",
    "This workbook contains an implementation of a linear regression model which is applied on a cleaned dataset\n",
    "along with the original dataset that was distoted to create dirty data. All codeblocks have a comment block explaining what that code is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing modules to use\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sepal length  sepal width  petal length  petal width  \\\n",
       "0           0          10.2          7.0           5.6          0.8   \n",
       "1           1           9.8          6.0           5.6          0.8   \n",
       "2           2           9.4          6.4           5.2          0.8   \n",
       "3           3           9.2          6.2           6.0          0.8   \n",
       "4           4          10.0          7.2           5.6          0.8   \n",
       "\n",
       "        target  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reading data from excel file and checking if data has been read correctly.\n",
    "\"\"\"\n",
    "\n",
    "data=pd.read_excel('cleaned data.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width       target\n",
       "0          10.2          7.0           5.6          0.8  Iris-setosa\n",
       "1           9.8          6.0           5.6          0.8  Iris-setosa\n",
       "2           9.4          6.4           5.2          0.8  Iris-setosa\n",
       "3           9.2          6.2           6.0          0.8  Iris-setosa\n",
       "4          10.0          7.2           5.6          0.8  Iris-setosa"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dropping the first column of indexes as it is redundant.\n",
    "\"\"\"\n",
    "\n",
    "data=data.drop([data.columns[0]],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width target\n",
       "0          10.2          7.0           5.6          0.8      1\n",
       "1           9.8          6.0           5.6          0.8      1\n",
       "2           9.4          6.4           5.2          0.8      1\n",
       "3           9.2          6.2           6.0          0.8      1\n",
       "4          10.0          7.2           5.6          0.8      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now before a model can be implemented there is a need to change the output variable (target) to a neumeric value\n",
    "rather than string. So, following convnetion is used:\n",
    "1: Iris-setosa\n",
    "2: Iris-versicolor\n",
    "3: Iris-virginica\n",
    "\"\"\"\n",
    "\n",
    "data.loc[data[\"target\"] == \"Iris-setosa\", \"target\"] = 1\n",
    "data.loc[data[\"target\"] == \"Iris-versicolor\", \"target\"] = 2\n",
    "data.loc[data[\"target\"] == \"Iris-virginica\", \"target\"] = 3\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here the data frame is split into training and testing data on a 80:20 ratio. This is done to validate the results\n",
    "after training to know how well the model has performed.\n",
    "\"\"\"\n",
    "\n",
    "train,test=train_test_split(data,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>22.4</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width\n",
       "4            10.0          7.2           5.6          0.8\n",
       "26           10.4          7.0           6.0          0.8\n",
       "123          12.2          6.0          19.6          7.2\n",
       "128          12.8          5.6          22.4          8.8\n",
       "16           10.2          7.0           5.6          1.2\n",
       "..            ...          ...           ...          ...\n",
       "71           13.2          6.0          17.6          5.6\n",
       "106          13.0          6.4          20.4          8.0\n",
       "14           11.6          8.0           4.8          0.8\n",
       "92           11.4          5.8          16.8          5.2\n",
       "102           9.8          5.0          18.0          6.8\n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here the x and y parameters for use in model are being declared.\n",
    "\"\"\"\n",
    "\n",
    "# x=train[['sepal length','sepal width','petal length','petal width']]\n",
    "x=train.iloc[:,:-1]\n",
    "y=train['target']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now that all variables are defined it is simple to apply a multi-variable regression model on data.\n",
    "This block trains the regression model.\n",
    "\"\"\"\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88671757, 2.77571872, 0.88280401, 0.93009948, 1.00958646,\n",
       "       2.90594134, 0.99723601, 2.43218961, 2.61347918, 0.97322177,\n",
       "       0.88867484, 2.49209517, 2.90777538, 2.04966604, 2.8517452 ,\n",
       "       0.92225253, 2.05808309, 3.06549159, 1.0005341 , 2.16836794,\n",
       "       3.28032015, 2.5803357 , 0.99012108, 2.09035866, 0.89733168,\n",
       "       2.1494925 , 2.33748263, 3.01231264, 3.20421631, 0.89733168])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now that model is trained, testing data can be used to validate model. This code block extracts testing data's\n",
    "input parameters and uses them to generate a prediction from trained model.\n",
    "\"\"\"\n",
    "\n",
    "prediction=regr.predict(test.iloc[:,:-1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 1, 1, 3, 1, 2, 3, 1, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 3,\n",
       "       1, 2, 1, 2, 2, 3, 3, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The output from regression model is not integral but rather whole numbers. However the model has specific labels\n",
    "and this continuous output needs to be discretized. So, the output of model is rounded to nearest integer.\n",
    "\"\"\"\n",
    "\n",
    "y_pred=np.rint(prediction).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now that model has been trained, there is a need to validate model's output to asses accuracy on given dataset.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_training_size=len(train)\n",
    "cleaned_testing_size=len(test)\n",
    "cleaned_accuracy_score=accuracy_score(test['target'].tolist(),y_pred.tolist()) # accuracy score\n",
    "cleaned_squared_error=mean_squared_error(test['target'].tolist(),y_pred.tolist()) # mean squared error\n",
    "cleaned_dett_coeff=r2_score(test['target'].tolist(),y_pred.tolist()) # coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here all the code blocks are combined into one to perform same operations on original data.\n",
    "The validation results are stored for later use.\n",
    "\"\"\"\n",
    "\n",
    "data=pd.read_excel('Original Iris.xlsx') # reading data file into a dataframe\n",
    "\n",
    "data=data.drop([data.columns[0]],axis=1) # dropping the index column\n",
    "\n",
    "# transforming output variables for use in the model\n",
    "data.loc[data[\"target\"] == \"Iris-setosa\", \"target\"] = 1\n",
    "data.loc[data[\"target\"] == \"Iris-versicolor\", \"target\"] = 2\n",
    "data.loc[data[\"target\"] == \"Iris-virginica\", \"target\"] = 3\n",
    "\n",
    "train,test=train_test_split(data,test_size=0.2,random_state=42,shuffle=True) # splitting data into training and testing datasets\n",
    "\n",
    "# Separating input and output variables form training data to use in model\n",
    "x=train.iloc[:,:-1]\n",
    "y=train['target']\n",
    "\n",
    "# fitting regression model on given dataset\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x, y)\n",
    "\n",
    "prediction=regr.predict(test.iloc[:,:-1]) # storing prediction based on testing data\n",
    "\n",
    "y_pred=np.rint(prediction).astype(int) # converting continuous predicted output to nearest integer\n",
    "\n",
    "# calculating and storing validation parameters\n",
    "original_training_size=len(train)\n",
    "original_testing_size=len(test)\n",
    "original_accuracy_score=accuracy_score(test['target'].tolist(),y_pred.tolist()) # accuracy score\n",
    "original_squared_error=mean_squared_error(test['target'].tolist(),y_pred.tolist()) # mean squared error\n",
    "original_dett_coeff=r2_score(test['target'].tolist(),y_pred.tolist()) # coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Dirty Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here all the code blocks are combined into one to perform same operations on original data.\n",
    "The validation results are stored for later use.\n",
    "\"\"\"\n",
    "\n",
    "data=pd.read_excel('my_iris.xlsx') # reading data file into a dataframe\n",
    "\n",
    "data=data.dropna()\n",
    "\n",
    "data=data.drop([data.columns[0]],axis=1) # dropping the index column\n",
    "\n",
    "# transforming output variables for use in the model\n",
    "data.loc[data[\"target\"] == \"Iris-setosa\", \"target\"] = 1\n",
    "data.loc[data[\"target\"] == \"Iris-versicolor\", \"target\"] = 2\n",
    "data.loc[data[\"target\"] == \"Iris-virginica\", \"target\"] = 3\n",
    "\n",
    "train,test=train_test_split(data,test_size=0.2,random_state=42,shuffle=True) # splitting data into training and testing datasets\n",
    "\n",
    "# Separating input and output variables form training data to use in model\n",
    "x=train.iloc[:,:-1]\n",
    "y=train['target']\n",
    "\n",
    "# fitting regression model on given dataset\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x, y)\n",
    "\n",
    "prediction=regr.predict(test.iloc[:,:-1]) # storing prediction based on testing data\n",
    "\n",
    "y_pred=np.rint(prediction).astype(int) # converting continuous predicted output to nearest integer\n",
    "\n",
    "# calculating and storing validation parameters\n",
    "dirty_training_size=len(train)\n",
    "dirty_testing_size=len(test)\n",
    "dirty_accuracy_score=accuracy_score(test['target'].tolist(),y_pred.tolist()) # accuracy score\n",
    "dirty_squared_error=mean_squared_error(test['target'].tolist(),y_pred.tolist()) # mean squared error\n",
    "dirty_dett_coeff=r2_score(test['target'].tolist(),y_pred.tolist()) # coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark: \n",
      "\n",
      "Parameters for original dataset (120 training examples, 30 testing examples) are as follows:\n",
      "  1. Accuracy Score is:1.0\n",
      "  2. Mean squared error: 0.00\n",
      "  3. Coefficient of determination: 1.00\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "Parameters for dirty dataset (80 training examples, 20 testing examples) are as follows:\n",
      "  1. Accuracy Score is:0.95\n",
      "  2. Mean squared error: 0.05\n",
      "  3. Coefficient of determination: 0.91\n",
      "\n",
      "Parameters for cleaned dataset (116 training examples, 30 testing examples) are as follows:\n",
      "  1. Accuracy Score is:0.9333333333333333\n",
      "  2. Mean squared error: 0.07\n",
      "  3. Coefficient of determination: 0.91\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This blocks prints the values of all validation vaiables used to compare the implementation on different datasets.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Benchmark: \\n\")\n",
    "print(f\"Parameters for original dataset ({original_training_size} training examples, {original_testing_size} testing examples) are as follows:\")\n",
    "print(f\"  1. Accuracy Score is:{original_accuracy_score}\",)\n",
    "# The mean squared error\n",
    "print(\"  2. Mean squared error: %.2f\" % original_squared_error)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"  3. Coefficient of determination: %.2f\" % original_dett_coeff)\n",
    "\n",
    "print(f\"\\n-----------------------------------------------------------------\\n\")\n",
    "\n",
    "print(f\"Parameters for dirty dataset ({dirty_training_size} training examples, {dirty_testing_size} testing examples) are as follows:\")\n",
    "print(f\"  1. Accuracy Score is:{dirty_accuracy_score}\",)\n",
    "# The mean squared error\n",
    "print(\"  2. Mean squared error: %.2f\" % dirty_squared_error)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"  3. Coefficient of determination: %.2f\" % dirty_dett_coeff)\n",
    "\n",
    "print(f\"\\nParameters for cleaned dataset ({cleaned_training_size} training examples, {cleaned_testing_size} testing examples) are as follows:\")\n",
    "print(f\"  1. Accuracy Score is:{cleaned_accuracy_score}\",)\n",
    "# The mean squared error\n",
    "print(\"  2. Mean squared error: %.2f\" % cleaned_squared_error)\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"  3. Coefficient of determination: %.2f\" % cleaned_dett_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Coefficient of Determination')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWMAAAF1CAYAAACNlPjlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7rElEQVR4nO3debhlZ1Un/u8yIYzBMFQwZCBRIxBoGSxD/Em3CCJJFIPdoIlgQhpNBwIOrULAARzoprFFpBnSEcIgSEDG0o5AjCJiE0gCIRAiUAZMigRSzEOEdHD9/ti74HC5VXWn2nf6fJ7nPvfsd79773Xuqbvqveu8+z3V3QEAAAAAYN/6jtUOAAAAAABgM1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMAHFWAAAAACACSjGsmlV1dOq6sWrHQcAAKy2qnpZVf3BascBrD1Vdfeqel9Vfamqfqmqbl1Vf1lVX6iqv6iqR1fV2xZwnjXzN3hVPb6qPlVVX66qO612PCuhqq6sqgfto3OfU1W/vS/OvRkpxrLPVNXHq+pfx4T9+ar6v1V1ZlUt6N9dVR1ZVV1V+y8jhpOq6vKq+mJVfbqqLqqqI5Oku/9bd//CUs8NsNKq6u1V9bmquuVqx7KvjIPwj40D3x1V9ZrVjglYv8bx5k1Vdec57ZeP48gjVyGmDZfnquqxVfX18TnNft11tWMDvqmqfq6qLh1/P6+vqr+uqgeuwKmfnOTt3X1gdz8vySOT3CXJnbr7Ud39qu7+8b2dZKX+Bl9uraCqbpHkOUl+vLtv192f2c35d+W6T1XVX1XVQxdxjWdU1SuXEt9Sdfe9uvvtyz3PmPPfOefcZ3b37y/33AwUY9nXHt7dBya5W5JnJXlKkpdMceGq+t4kr0jya0m+M8lRSV6Y5N+muD7AYowFg3+fpJP81MTXXvKbXou8zmlJfj7Jj3X37ZJsTXLRCl9jkucCrCkfS3LKro2q+ndJbr0agUyR5xYYx77Ihe8aixazX9ct5NqLjUcuh8Wrqv+a5LlJ/luGQukRGf7+PWkFTn+3JFfO2f5Id9+8AudeDXdJcqt863Oaz0FjLr9PkguTvLGqHruPY0siD250irFMoru/0N3bkvxsktOq6t5JUlU/Md7u8MWquraqnjFz2DvG758f3436oar6nqr626r6zDjT9VVVddBuLnvfJB/r7ot68KXufn13XzNe+xvvVFXV8+e8y3/zrliq6q5V9fqq2jnOcvillf75ACQ5NcnFSV6W5LTZHVV1eFW9YcxDn6mq58/s+8Wqumq8C+FDVXX/sb3HN6V29fvG7adV9aBxttZTquqTSV5aVXcY3/HfOc7O/auqOmzm+DtW1Uur6rpx/5vG9g9W1cNn+t1izM/3nec5/mCSt3b3PydJd3+yu8/d2zVmnuf2qvpsVW2bnY01PtezquqjST46tv3kODNu150Z37/gVwJYb/4sQw7d5bQMb8h/Q1Xdsqr+Z1VdM85wOqeqbj3u21v+e3tV/X5V/eOYa99Wc2bizthbnjuqqv5+PM+F4xh013j0QVW1Y07cH6+qHxsfH1tV7xrz2vXjsQfM9F1ULqyq+1XVe8dYXpOhMLEkY5xPqaorknylqr53jOdxVXVNkr+tqu+oqt+qqn+pqhuq6hVV9Z3j8UfO7b/UWGAzGn+Xfi/JWd39hu7+Snf/v+7+y+7+jbHPLavqueM467rx8S1nzjFvvqiqv03yo0l2/c386iS/k+Rnx+3H1ZyZlFV1rzHHfXbMuU8b279ltmhVHTde6/NV9f6aucV+L7n322oF8/xM5n2+VfV9ST48c/xe882Yy/8kyTOS/I8a7/at3dQKqur4JE+b+Rm9f9frVFUvGXP4J6rqD6pqv3HfY8fn+sdV9dkkz6hh/P7CGmY4f3nc/13jc/lcVf1TVd1v5jnP/p/xjKp67Zhrv1TDEgZbZ/qeXVX/XN/8G+Knx/Z7JjknyQ+N1/z82P4tS9nU3sfmZ1bVR8c4X1BVtbef82aiGMukuvs9SXZkmP2VJF/JMHg+KMlPJHl8VT1i3Pcfxu8Hje+8vytJJfnvSe6a5J5JDs+QEOfz3iT3GJPZj1bV7fYQ1xN3vcOf5IFJPpfkzWOS/csk709yaJKHJPmVqnrYYp87wF6cmuRV49fDquouSTIO0P4qyb8kOTJDLjp/3PeoDDnw1CS3zzCj9jNZmO9KcscMMxvOyDAmeOm4fUSSf03y/Jn+f5bkNknuleTgJH88tr8iyWNm+p2Y5Pruvnyea16c5NSq+o2q2rpr8Lm3a1TVgzPk/p9JckiGn8X5c459RJIHJDmmhoL0eUn+S5I7JfnfSbbVBl7+ATa5i5PcvqruOeaVn00y99bQ/5Hk+zK8Wf+9GXLp74z79pb/kuTnkpyeITcdkOTX9xDLnvLcnye5LMmdk/x+5rz5thdfT/Kr47E/lGFc+oQ5fR6RBeTCGoq4b8qQd++Y5C+S/KdFxDKfUzKM5w9Ksmu23I9kGLM/LMljx68fTfLdSW6Xb/85z/YHFu6HMryh8sY99PnNJMdlyIP3SXJskt9Kkj3li+5+cJJ/SLLrb+ZTMsy+fc24/S13vlbVgUn+JslbMvzd/r2Z5w6Bqjo0yf9J8gcZ8tCvJ3l9VW2Z6ba73DtfrWBBz7e7P5JhrLnr+Afv4Wc21xvGWO6+p1pBd78l3/ozus94/Msz5MfvTXK/JD+eZHbZhgckuXq8xjPHtp/J8DrdOcnXkrwrQ63jzklel2G5hd35qQxj5oOSbMu35tx/zlCX+c4kv5vklVV1SHdfleTMfPNuiIPmnnSBY/OfzPAG5X3GfvL6DMVYVsN1GZJtuvvt3f2B7v637r4iyaszDMLm1d3bu/vC7v5ad+/MkHjm7d/dVyd5UIbE+Noknx7fzdltUXZM/G9K8qTufl+G5LGlu3+vu28az/mnSU5e9LMG2I0a1vK6W5LXdvdlGQZHPzfuPjbDQPY3xlkOX+3uXTMPfiHJs7v7kvEOgO3d/S8LvOy/JXn6mE//tbs/M949cGN3fynDAPBHxvgOSXJCkjO7+3PjTIu/H8/zyiQnVtXtx+2fz/DH/bfp7lcmeVKGwdjfJ7mhqs5ewDUeneS87n5vd38tyVMzvFt/5Mzp/3t3f7a7/zXJLyb539397u7+ene/PMPg9bgF/myA9WfX7NiHJvmnJJ/YtWOcjfOLSX51zBNfyvBH8slJsqf8N+Ol3f2RMce8NsMf999mL3nuiAxjy98ec+87MvwhvyDdfVl3X9zdN3f3xzMUS+bGudBceFySWyR57phvX5fkkr2EcNw4e23X1z/P2f+87r52vPYuzxj/7/rXDLn8Od19dXd/OUMuP7m+9Vbc2f7Awt0pyaf3smzAo5P8XnffMP4t/bsZxm3Jyo6dfjLJJ7v7j8Zx65e6+93z9HtMkgu6+4KxHnBhkkszvLG/y4Jy727s6fku1a6lWe6YRdYKxokWJyT5lTHP3ZBh4sFs/+u6+3+NeX5XHnzjmP+/mqHY/tXufkV3fz3JazIUdXfnnePP9+sZ/p/cVRROd/9Fd183/uxfk+GOimMX+HNYyNj8Wd39+R7uTP67LO612/CsQcFqODTJZ5Okqh6QYS3Ze2d4p+uWGd6Zn1dVHZzkeRnewTkwwxsKn9td/+6+OMO7MKmqH8yQrH4zQ7KYe+5bZHhn6c+7e9e7OndLctddU/NH+2V4ZxBgpZyW5G3d/elx+8/Htj/OcAfAv+xmcH14hsLtUuwcB3VJkqq6zXi945PcYWw+cJzVdXiSz3b3t+Xb7r6uqv4xyX+qqjdmGGT+8u4u2t2vSvKqMec+Ynz8vgy5fN5rZChGv3fmHF+uqs9k+P/k42PztTP975ZhSZwnzbQdMJ4H2Jj+LMNtq0dlzhIFSbZkmHV/2cxdkpVhTLfH/Df+AZskn5w5340ZZnXOaw957gtJPtfdX5np/i8Zcuxe1XBr7XMyrEN7mwx/y102p9tCc2En+UR395xY9uTi7t7TBwFdu5e2u865xr9keA532cs5gL37TJI7V9X+eyjIzvc7uGtstJJjp4WOT++W5FE1s9xVhjeJ/m5me8G5dx57er5Ldej4/bNJ/l0WVyu4W4bnd/3M/0XfkW/Ne/PlwE/NPP7Xebb39DOZ+/O71a5/I1V1apL/muHOu4zn2d0SPHMtZGy+nNduwzMzlkmNBdFDk+ya1fXnGabLH97d35lhbZJdmam//Qz572P793f37TO8m7agtUe6+5IMtxXcezdd/leSL2W8VWN0bYZ1Zw+a+Tqwu0+c/xQAi1PDmoU/k+RHquqTNazh+qtJ7lNV98mQh46o+RfxvzbJ9+zm1Ddm+GN9l++as39ujv21JHdP8oAxv+66/avG69yxdr9G98sz5ONHZbil6RO76ffNiw8zsf4iyRUZ8vKernFdhgHsEFDVbTPMAJm9zuzzuTbJM+fk7tt096v3FhewPvVwV8DHMsyoesOc3Z/O8AfrvWZywnf2sDxVsuf8t5yY5ua565PcYcxhuxwx8/grmcnb45ths7frvijDrN+jxzifNk+MC82F1yc5dM4afkdkeeYbu8+2fUsuH693c761sDDfOYC9e1eSr2Z4A2h35vsd3DXTcyXHTnsan87t92dzrnnb7n7WAo5dSK7Y0/Ndqp9OckOGNWf3ViuYG+O1GWYb33mm/+27+14zfSbJgVV1twyzeJ+Y5E49LEXwwey5FjNrIWNz9kAxlklU1e2r6iczrCPyyu7+wLjrwAwzob5aVcfmm7flJsnODLfRfvdM24FJvpxhoe1Dk/zGHq75wHFR6YPH7XtkWDPl4nn6/pcMt3n9XHf/28yu9yT5Yg0fSHDrqtqvqu49FpUBVsIjMqwDeEyG23fum2G9vH/IcMvtezL80fysqrptVd2qqn54PPbFSX69qn6gBt87Dq6S5PIkPzfmreOzhyVgRgdmKFZ8vqrumOTpu3Z09/VJ/jrJC2v4oJtbVNV/mDn2TUnun2FG7NwZad9QwwcT/ERVHVjDB7mckGHNrnfv5Rp/nuT0qrrvuO7rfxuP+fhuLvWnSc6sqgeMP5fb7rruXn4GwPr2uCQPnjPzNOPY7k+T/PHMuPDQ+uZnAOw2/y3WXvLcv2S4Bfd3q+qAcYma2RlhH8kwa+knxlm1v5XhrrFdDkzyxSRfHse1j99LOHvKhe/KUAj9parav6r+YxZ+e+pSvTrJr9bwIWa3yzfXU1yvn8YOa0Z3fyHDOtgvqKpHVNVtxrHUCVX17LHbq5P8VlVtqeGDsH4n31xfeyXHTn+V5Luq6ldqWKP6wBruiJ3rlUkeXlUPG8ert6rhgwwPm6fvXPPVCuba0/NdlKq6S1U9McP/D08d/1/ZW63gU0mOrPHDvsax7tuS/NFYH/mOGj6gfG9j9H3hthkKrjuTpKpOz7dOWvtUksNq5kMi51js2Jw5FGPZ1/6yqr6U4V2g38xwa9XpM/ufkOT3xj6/k2EdmCRJd9+YYc2uf6xhXarjMqzzcv8Mt3n9n3z7zIdZn89QfP1AVX05wwLib0zy7Hn6npIhkV9XwycGfrmqnjbemvbwDMWRj2WYWfHiDItcA6yE0zKsh3VND5/U+snu/mSGBfYfneEd6odnWOj/mgwfgvizybDWU4Y8+ecZZva/KeOa3BkKow/PkAsfPe7bk+cmuXWGPHdxhpw56+eT/L8Ms7JuSPIru3aMa1q9PsPtwXvKy1/MMJPrmjGuZyd5fH9zDdx5r9HdFyX57fEa12eYbbHbtbu7+9IMa589P8PyB9szfGgMsIF19z+Pv//zeUqGXHBxVX0xw4fL3H3c99zsOf8txt7y3M9l+ICWz2b4o/4bb2CNxZQnZBhrfiLDTNkdM+f+9fH4L2UonLxmT4HsKRd2901J/uO4/bkM/6/sKX8n3/xk7dmvxUxQOC/fXE7iYxlm8T1pj0cAC9bdz8lw2/lvZSiyXZth5uObxi5/kOENoSuSfCDDbeZ/MB67YmOnHtbefmiGcegnM6xF+qPz9Ls2yUkZcuaueH8jC6hT7aZWMNdun+8ifL6qvjIef2KSR3X3eWMMe6sV7Fp+8TNVteuW/lMzLP/woQw/59dl+ACsSXX3h5L8UYY35j6VYcmFf5zp8rdJrkzyyar69DzHL2pszrerb10mCABg8arqd5J8X3c/ZrVjAVgvquoZSb5X7gSAzcMHeAEAyzLe1vu4LP8TagEAADY0yxQAAEtWVb+Y4bayv+7ud6x2PLAQVXV8VX24qrZX1dnz7K+qet64/4qquv/Yfvequnzm64tV9SuTPwEAANYtyxQAALBp1PAJ9R/JsJ7djiSXJDllXD9tV58TM6xleWKG9T3/pLsfMM95PpHkAeMHMwEAwF6ZGQsAwGZybJLt3X31+CFG52f4AJFZJyV5RQ8uTnJQVc39gI2HJPlnhVgAABZDMRYAgM3k0AxLa+yyY2xbbJ+Tk7x6xaMDAGBDWxMf4HXnO9+5jzzyyNUOA9jkLrvssk9395bVjmMK8i6wFqxS3q152uau27XHPlV1QJKfSvLU3V6k6owkZyTJbW972x+4xz3usfhIAVbQZhnrGucCa8Xu8u6aKMYeeeSRufTSS1c7DGCTq6pNc6upvAusBauUd3ckOXxm+7Ak1y2yzwlJ3tvdn9rdRbr73CTnJsnWrVtbzgVW22YZ6xrnAmvF7vKuZQoAANhMLklydFUdNc5wPTnJtjl9tiU5tQbHJflCd18/s/+UWKIAAIAlWBMzYwEAYArdfXNVPTHJW5Psl+S87r6yqs4c95+T5IIkJybZnuTGJKfvOr6qbpPkoUn+y9SxAwCw/inGAgCwqXT3BRkKrrNt58w87iRn7ebYG5PcaZ8GCADAhmWZAgAAAACACSjGAgAAAABMQDEWAAAAAGACirEAAAAAABNQjAUAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLsIZV1XlVdUNVfXA3+6uqnldV26vqiqq6/9QxAgDAUhjrApuRYizA2vayJMfvYf8JSY4ev85I8qIJYgIAgJXwshjrApuMYizAGtbd70jy2T10OSnJK3pwcZKDquqQaaIDAIClM9YFNqP9VzuAxfi1v37FaoewLv3RCaeudgjAvnNokmtntneMbdfP7VhVZ2SYUZAjjjhiryeWc5dGzgVYv2540ZNXO4R15+DHP3u1Q2BjW9BYd7Hj3MRYd6mMdWH5zIwFWN9qnraer2N3n9vdW7t765YtW/ZxWAAAsGwLGusa5wLriWIswPq2I8nhM9uHJblulWIBAICVZKwLbDiKsQDr27Ykp46fNHtcki9097ctUQAAAOuQsS6w4ayrNWMBNpuqenWSByW5c1XtSPL0JLdIku4+J8kFSU5Msj3JjUlOX51IAQBgcYx1gc1IMRZgDevuU/ayv5OcNVE4AACwYox1gc3IMgUAAAAAABNQjAUAAAAAmIBlCliUG1705NUOYV06+PHPXu0QAAAAAFhlZsYCAAAAAExAMRYAAAAAYAKKsQAAAAAAE1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMIH9VzsAAIC16oWvfOdqh7AuPeExD1ztEAAAYE3a68zYqjqvqm6oqg/Os+/Xq6qr6s4zbU+tqu1V9eGqethKBwwAAAAAsB4tZJmClyU5fm5jVR2e5KFJrplpOybJyUnuNR7zwqrab0UiBQAAAABYx/ZajO3udyT57Dy7/jjJk5P0TNtJSc7v7q9198eSbE9y7EoECgAAAACwni3pA7yq6qeSfKK73z9n16FJrp3Z3jG2AQAAAABsaov+AK+quk2S30zy4/Ptnqet52lLVZ2R5IwkOeKIIxYbBgBseDe86MmrHcK6dPDjn73aIQAAAMxrKTNjvyfJUUneX1UfT3JYkvdW1XdlmAl7+Ezfw5JcN99Juvvc7t7a3Vu3bNmyhDAAAAAAANaPRRdju/sD3X1wdx/Z3UdmKMDev7s/mWRbkpOr6pZVdVSSo5O8Z0UjBgAAAABYh/ZajK2qVyd5V5K7V9WOqnrc7vp295VJXpvkQ0nekuSs7v76SgULAAAAALBe7XXN2O4+ZS/7j5yz/cwkz1xeWAAAAAAAG8tS1owFAAAAAGCRFGMBAAAAACaw12UKAABgI6mq45P8SZL9kry4u581Z3+N+09McmOSx3b3e8d9ByV5cZJ7J+kk/7m73zVd9AAAK+OFr3znaoewLj3hMQ9c1vGKsQAAbBpVtV+SFyR5aJIdSS6pqm3d/aGZbickOXr8ekCSF43fk6FI+5bufmRVHZDkNpMFDwAbyA0vevJqh7AuHfz4Z692CCyTZQoAANhMjk2yvbuv7u6bkpyf5KQ5fU5K8ooeXJzkoKo6pKpun+Q/JHlJknT3Td39+QljBwBgnVOMBQBgMzk0ybUz2zvGtoX0+e4kO5O8tKreV1UvrqrbzneRqjqjqi6tqkt37ty5ctEDALCuKcYCALCZ1DxtvcA++ye5f5IXdff9knwlydnzXaS7z+3urd29dcuWLcuJFwCADUQxFgCAzWRHksNntg9Lct0C++xIsqO73z22vy5DcRYAABZEMRYAgM3kkiRHV9VR4wdwnZxk25w+25KcWoPjknyhu6/v7k8mubaq7j72e0iSDwUAABZo/9UOAAAAptLdN1fVE5O8Ncl+Sc7r7iur6sxx/zlJLkhyYpLtSW5McvrMKZ6U5FVjIffqOfsAAGCPFGMBANhUuvuCDAXX2bZzZh53krN2c+zlSbbuy/gAANi4LFMAAAAAADABxVgAAAAAgAkoxgIAAAAATEAxFgAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExAMRYAAAAAYAKKsQAAAAAAE1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMAHFWAAAAACACSjGAgAAAABMQDEWAAAAAGACirEAAAAAABNQjAUAAAAAmMBei7FVdV5V3VBVH5xp+8Oq+qequqKq3lhVB83se2pVba+qD1fVw/ZR3ACbQlUdP+bT7VV19jz7v7Oq/rKq3l9VV1bV6asRJwAALJaxLrAZLWRm7MuSHD+n7cIk9+7u70/ykSRPTZKqOibJyUnuNR7zwqrab8WiBdhExvz5giQnJDkmySljnp11VpIPdfd9kjwoyR9V1QGTBgoAAItkrAtsVnstxnb3O5J8dk7b27r75nHz4iSHjY9PSnJ+d3+tuz+WZHuSY1cwXoDN5Ngk27v76u6+Kcn5GfLsrE5yYFVVkttlyNc3BwAA1jZjXWBTWok1Y/9zkr8eHx+a5NqZfTvGtm9TVWdU1aVVdenOnTtXIAyADWchOfX5Se6Z5LokH0jyy939b/OdTN4FAGANWbGxrnEusJ4sqxhbVb+Z4V2pV+1qmqdbz3dsd5/b3Vu7e+uWLVuWEwbARrWQnPqwJJcnuWuS+yZ5flXdfr6TybsAAKwhKzbWNc4F1pMlF2Or6rQkP5nk0d29K2HuSHL4TLfDMryDBcDiLSSnnp7kDT3YnuRjSe4xUXwAALBUxrrAprSkYmxVHZ/kKUl+qrtvnNm1LcnJVXXLqjoqydFJ3rP8MAE2pUuSHF1VR40fVHByhjw765okD0mSqrpLkrsnuXrSKAEAYPGMdYFNaf+9daiqV2f41MI7V9WOJE9P8tQkt0xy4bCOdi7u7jO7+8qqem2SD2VYvuCs7v76vgoeYCPr7pur6olJ3ppkvyTnjXn2zHH/OUl+P8nLquoDGW71ekp3f3rVggYAgAUw1gU2q70WY7v7lHmaX7KH/s9M8szlBAXAoLsvSHLBnLZzZh5fl+THp44LAACWy1gX2IyW9QFeAAAAAAAsjGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMAHFWAAAAACACSjGAgAAAABMQDEWAIBNpaqOr6oPV9X2qjp7nv1VVc8b919RVfef2ffxqvpAVV1eVZdOGzkAAOvd/qsdAAAATKWq9kvygiQPTbIjySVVta27PzTT7YQkR49fD0jyovH7Lj/a3Z+eKGQAADYQM2MBANhMjk2yvbuv7u6bkpyf5KQ5fU5K8ooeXJzkoKo6ZOpAAQDYeBRjAQDYTA5Ncu3M9o6xbaF9Osnbquqyqjpjn0UJAMCGZJkCAAA2k5qnrRfR54e7+7qqOjjJhVX1T939jm+7yFCoPSNJjjjiiOXEC5vKC1/5ztUOYd15wmMeuNohALAIZsYCALCZ7Ehy+Mz2YUmuW2if7t71/YYkb8yw7MG36e5zu3trd2/dsmXLCoUOAMB6pxgLAMBmckmSo6vqqKo6IMnJSbbN6bMtyak1OC7JF7r7+qq6bVUdmCRVddskP57kg1MGDwDA+maZAgAANo3uvrmqnpjkrUn2S3Jed19ZVWeO+89JckGSE5NsT3JjktPHw++S5I1VlQzj6D/v7rdM/BQAAFjHFGMBANhUuvuCDAXX2bZzZh53krPmOe7qJPfZ5wECALBhWaYAAAAAAGACirEAAAAAABNQjAUAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLAAAAADABxVgAAAAAgAkoxgIAAAAATEAxFgAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExAMRYAAAAAYAJ7LcZW1XlVdUNVfXCm7Y5VdWFVfXT8foeZfU+tqu1V9eGqeti+ChwAAAAAYD1ZyMzYlyU5fk7b2Uku6u6jk1w0bqeqjklycpJ7jce8sKr2W7FoAQAAAADWqb0WY7v7HUk+O6f5pCQvHx+/PMkjZtrP7+6vdffHkmxPcuzKhAoAAAAAsH4tdc3Yu3T39Ukyfj94bD80ybUz/XaMbQAAAAAAm9r+K3y+mqet5+1YdUaSM5LkiCOOWOEwYON64SvfudohrEtPeMwDVzsEAAAAYJNb6szYT1XVIUkyfr9hbN+R5PCZfocluW6+E3T3ud29tbu3btmyZYlhAAAAAACsD0stxm5Lctr4+LQkb55pP7mqbllVRyU5Osl7lhciAAAAAMD6t9dlCqrq1UkelOTOVbUjydOTPCvJa6vqcUmuSfKoJOnuK6vqtUk+lOTmJGd199f3UewAAAAAAOvGXoux3X3KbnY9ZDf9n5nkmcsJCgAAAABgo1nqMgUAAAAAACyCYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExAMRYAAAAAYAKKsQAAAAAAE1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMAHFWIA1rKqOr6oPV9X2qjp7N30eVFWXV9WVVfX3U8cIsN7sLbfW4Hnj/iuq6v5z9u9XVe+rqr+aLmqAjcdYF9iM9l/tAACYX1Xtl+QFSR6aZEeSS6pqW3d/aKbPQUlemOT47r6mqg5elWAB1omF5NYkJyQ5evx6QJIXjd93+eUkVyW5/SRBA2xAxrrAZmVmLMDadWyS7d19dXfflOT8JCfN6fNzSd7Q3dckSXffMHGMAOvNQnLrSUle0YOLkxxUVYckSVUdluQnkrx4yqABNiBjXWBTUowFWLsOTXLtzPaOsW3W9yW5Q1W9vaouq6pTd3eyqjqjqi6tqkt37ty5D8IFWBcWklv31Oe5SZ6c5N/2dBE5F2CvVmysK+cC64liLMDaVfO09Zzt/ZP8QIZZWg9L8ttV9X3znay7z+3urd29dcuWLSsbKcD6sZDcOm+fqvrJJDd092V7u4icC7BXKzbWlXOB9cSasQBr144kh89sH5bkunn6fLq7v5LkK1X1jiT3SfKRaUIEWHcWmlvn6/PIJD9VVScmuVWS21fVK7v7MfswXoCNylgX2JTMjAVYuy5JcnRVHVVVByQ5Ocm2OX3enOTfV9X+VXWbDB8wc9XEcQKsJwvJrduSnFqD45J8obuv7+6ndvdh3X3keNzfKsQCLJmxLrApmRkLsEZ1981V9cQkb02yX5LzuvvKqjpz3H9Od19VVW9JckWG9Qtf3N0fXL2oAda2heTWJBckOTHJ9iQ3Jjl9teIF2KiMdYHNSjEWYA3r7gsyFAVm286Zs/2HSf5wyrgA1rO95dbu7iRn7eUcb0/y9n0QHsCmYawLbEaWKQAAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLAAAAADABxVgAAAAAgAkoxgIAAAAATEAxFgAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwgWUVY6vqV6vqyqr6YFW9uqpuVVV3rKoLq+qj4/c7rFSwAAAAAADr1ZKLsVV1aJJfSrK1u++dZL8kJyc5O8lF3X10kovGbQAAAACATW25yxTsn+TWVbV/ktskuS7JSUlePu5/eZJHLPMaAAAAAADr3pKLsd39iST/M8k1Sa5P8oXufluSu3T39WOf65McPN/xVXVGVV1aVZfu3LlzqWEAAAAAAKwLy1mm4A4ZZsEeleSuSW5bVY9Z6PHdfW53b+3urVu2bFlqGAAAAAAA68Jylin4sSQf6+6d3f3/krwhyf+X5FNVdUiSjN9vWH6YAAAAAADr23KKsdckOa6qblNVleQhSa5Ksi3JaWOf05K8eXkhAgAAAACsf/sv9cDufndVvS7Je5PcnOR9Sc5Ncrskr62qx2Uo2D5qJQIFAAAAAFjPllyMTZLufnqSp89p/lqGWbIAAAAAAIyWs0wBAAAAAAALpBgLAAAAADABxVgAAAAAgAkoxgIAAAAATEAxFgAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExAMRYAAAAAYAKKsQAAAAAAE1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAwKZSVcdX1YerantVnT3P/qqq5437r6iq+4/tt6qq91TV+6vqyqr63emjBwBgPVOMBQBg06iq/ZK8IMkJSY5JckpVHTOn2wlJjh6/zkjyorH9a0ke3N33SXLfJMdX1XFTxA0AwMagGAsAwGZybJLt3X11d9+U5PwkJ83pc1KSV/Tg4iQHVdUh4/aXxz63GL96ssgBAFj3FGMBANhMDk1y7cz2jrFtQX2qar+qujzJDUku7O53z3eRqjqjqi6tqkt37ty5UrEDALDOKcYCALCZ1Dxtc2e37rZPd3+9u++b5LAkx1bVvee7SHef291bu3vrli1blhMvAAAbiGIsAACbyY4kh89sH5bkusX26e7PJ3l7kuNXPEIAADYsxVgAADaTS5IcXVVHVdUBSU5Osm1On21JTq3BcUm+0N3XV9WWqjooSarq1kl+LMk/TRg7AADr3P6rHQAAAEylu2+uqicmeWuS/ZKc191XVtWZ4/5zklyQ5MQk25PcmOT08fBDkry8qvbLMKnhtd39V1M/BwAA1i/FWAAANpXuviBDwXW27ZyZx53krHmOuyLJ/fZ5gAAAbFiWKQAAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLAAAAADABxVgAAAAAgAkoxgIAAAAATGBZxdiqOqiqXldV/1RVV1XVD1XVHavqwqr66Pj9DisVLMBmU1XHV9WHq2p7VZ29h34/WFVfr6pHThkfAAAslbEusBktd2bsnyR5S3ffI8l9klyV5OwkF3X30UkuGrcBWKSq2i/JC5KckOSYJKdU1TG76fc/krx12ggBAGBpjHWBzWrJxdiqun2S/5DkJUnS3Td19+eTnJTk5WO3lyd5xPJCBNi0jk2yvbuv7u6bkpyfIcfO9aQkr09yw5TBAQDAMhjrApvScmbGfneSnUleWlXvq6oXV9Vtk9ylu69PkvH7wSsQJ8BmdGiSa2e2d4xt31BVhyb56STnTBgXAAAsl7EusCktpxi7f5L7J3lRd98vyVeyiCUJquqMqrq0qi7duXPnMsIA2LBqnraes/3cJE/p7q/v9WTyLgAAa8eKjXWNc4H1ZDnF2B1JdnT3u8ft12Uozn6qqg5JkvH7vLcSdPe53b21u7du2bJlGWEAbFg7khw+s31Ykuvm9Nma5Pyq+niSRyZ5YVU9Yr6TybsAAKwhKzbWNc4F1pMlF2O7+5NJrq2qu49ND0nyoSTbkpw2tp2W5M3LihBg87okydFVdVRVHZDk5Aw59hu6+6juPrK7j8zwptgTuvtNk0cKAACLY6wLbEr7L/P4JyV51Zg4r05yeoYC72ur6nFJrknyqGVeA2BT6u6bq+qJGT45dr8k53X3lVV15rjf2lkAAKxLxrrAZrWsYmx3X57htoG5HrKc8wIw6O4Lklwwp23egWl3P3aKmAAAYCUY6wKb0XLWjAUAAAAAYIEUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExAMRYAAAAAYAKKsQAAAAAAE1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMAHFWAAAAACACSjGAgAAAABMQDEWAAAAAGACirEAAAAAABNQjAUAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLAAAAADABxVgAAAAAgAkoxgIAAAAATEAxFgAAAABgAoqxAABsKlV1fFV9uKq2V9XZ8+yvqnreuP+Kqrr/2H54Vf1dVV1VVVdW1S9PHz0AAOuZYiwAAJtGVe2X5AVJTkhyTJJTquqYOd1OSHL0+HVGkheN7Tcn+bXuvmeS45KcNc+xAACwW4qxAABsJscm2d7dV3f3TUnOT3LSnD4nJXlFDy5OclBVHdLd13f3e5Oku7+U5Kokh04ZPAAA65tiLAAAm8mhSa6d2d6Rby+o7rVPVR2Z5H5J3r3yIQIAsFEpxgIAsJnUPG29mD5Vdbskr0/yK939xXkvUnVGVV1aVZfu3LlzycECALCxKMYCALCZ7Ehy+Mz2YUmuW2ifqrpFhkLsq7r7Dbu7SHef291bu3vrli1bViRwAADWP8VYAAA2k0uSHF1VR1XVAUlOTrJtTp9tSU6twXFJvtDd11dVJXlJkqu6+znThg0AwEaw/2oHAAAAU+num6vqiUnemmS/JOd195VVdea4/5wkFyQ5Mcn2JDcmOX08/IeT/HySD1TV5WPb07r7ggmfAgAA65hiLAAAm8pYPL1gTts5M487yVnzHPfOzL+eLAAALIhlCgAAAAAAJqAYCwAAAAAwgWUXY6tqv6p6X1X91bh9x6q6sKo+On6/w/LDBAAAAABY31ZiZuwvJ7lqZvvsJBd199FJLhq3AQAAAAA2tWUVY6vqsCQ/keTFM80nJXn5+PjlSR6xnGsAAAAAAGwEy50Z+9wkT07ybzNtd+nu65Nk/H7wfAdW1RlVdWlVXbpz585lhgEAAAAAsLYtuRhbVT+Z5Ibuvmwpx3f3ud29tbu3btmyZalhAAAAAACsC/sv49gfTvJTVXViklsluX1VvTLJp6rqkO6+vqoOSXLDSgQKAAAAALCeLXlmbHc/tbsP6+4jk5yc5G+7+zFJtiU5bex2WpI3LztKAAAAAIB1brlrxs7nWUkeWlUfTfLQcRsAAAAAYFNbzjIF39Ddb0/y9vHxZ5I8ZCXOCwAAAACwUeyLmbEAAAAAAMyhGAsAAAAAMAHFWAAAAACACSjGAgAAAABMQDEWAAAAAGACirEAAAAAABNQjAUAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLAAAAADABxVgAAAAAgAkoxgKsYVV1fFV9uKq2V9XZ8+x/dFVdMX7936q6z2rECQAAi2WsC2xGirEAa1RV7ZfkBUlOSHJMklOq6pg53T6W5Ee6+/uT/H6Sc6eNEgAAFs9YF9isFGMB1q5jk2zv7qu7+6Yk5yc5abZDd//f7v7cuHlxksMmjhEAAJbCWBfYlBRjAdauQ5NcO7O9Y2zbnccl+et9GhEAAKwMY11gU9p/tQMAYLdqnraet2PVj2YYoD5wtyerOiPJGUlyxBFHrER8AACwVCs21jXOBdYTM2MB1q4dSQ6f2T4syXVzO1XV9yd5cZKTuvszuztZd5/b3Vu7e+uWLVtWPFgAAFiEFRvrGucC64liLMDadUmSo6vqqKo6IMnJSbbNdqiqI5K8IcnPd/dHViFGAABYCmNdYFOyTAHAGtXdN1fVE5O8Ncl+Sc7r7iur6sxx/zlJfifJnZK8sKqS5Obu3rpaMQMAwEIY6wKblWIswBrW3RckuWBO2zkzj38hyS9MHRcAACyXsS6wGVmmAAAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCALCpVNXxVfXhqtpeVWfPs7+q6nnj/iuq6v4z+86rqhuq6oPTRg0AwEagGAsAwKZRVfsleUGSE5Ick+SUqjpmTrcTkhw9fp2R5EUz+16W5Ph9HykAABuRYiwAAJvJsUm2d/fV3X1TkvOTnDSnz0lJXtGDi5McVFWHJEl3vyPJZyeNGACADUMxFgCAzeTQJNfObO8Y2xbbZ4+q6oyqurSqLt25c+eSAgUAYONRjAUAYDOpedp6CX32qLvP7e6t3b11y5YtizkUAIANbMnF2Ko6vKr+rqquqqorq+qXx/Y7VtWFVfXR8fsdVi5cAABYlh1JDp/ZPizJdUvoAwAAi7acmbE3J/m17r5nkuOSnDV++MHZSS7q7qOTXDRuAwDAWnBJkqOr6qiqOiDJyUm2zemzLcmpNTguyRe6+/qpAwUAYONZcjG2u6/v7veOj7+U5KoMa2mdlOTlY7eXJ3nEMmMEAIAV0d03J3likrdmGL++truvrKozq+rMsdsFSa5Osj3JnyZ5wq7jq+rVSd6V5O5VtaOqHjfpEwAAYF3bfyVOUlVHJrlfkncnucuumQPdfX1VHbybY85IckaSHHHEESsRBgAA7FV3X5Ch4Drbds7M405y1m6OPWXfRgcAwEa27A/wqqrbJXl9kl/p7i8u9DgfagAAAAAAbCbLKsZW1S0yFGJf1d1vGJs/VVWHjPsPSXLD8kIEAAAAAFj/llyMrapK8pIkV3X3c2Z2bUty2vj4tCRvXnp4AAAAAAAbw3LWjP3hJD+f5ANVdfnY9rQkz0ry2vHDDK5J8qhlRQgAAAAAsAEsuRjb3e9MUrvZ/ZClnhcAAAAAYCNa9gd4AQAAAACwd4qxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExAMRYAAAAAYAKKsQAAAAAAE1CMBQAAAACYgGIsAAAAAMAEFGMBAAAAACagGAsAAAAAMAHFWAAAAACACSjGAgAAAABMQDEWAAAAAGACirEAAAAAABNQjAUAAAAAmIBiLAAAAADABBRjAQAAAAAmoBgLAAAAADABxVgAAAAAgAkoxgIAAAAATEAxFgAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJqAYCwAAAAAwAcVYAAAAAIAJKMYCAAAAAExgnxVjq+r4qvpwVW2vqrP31XUANrK95dIaPG/cf0VV3X814gRYT5aTW41xAVaOsS6wGe2TYmxV7ZfkBUlOSHJMklOq6ph9cS2AjWqBufSEJEePX2ckedGkQQKsM8vJrca4ACvHWBfYrPbVzNhjk2zv7qu7+6Yk5yc5aR9dC2CjWkguPSnJK3pwcZKDquqQqQMFWEeWk1uNcQFWjrEusCntq2LsoUmundneMbYBsHALyaXyLcDiLCe3yrkAK8dYF9iU9t9H56152vpbOlSdkeE2gyT5clV9eB/FMpU7J/n0agcxn+fktNUOYSpr9jXIE/5wtSOYypp9Dc76+QV1u9s+DmOx9ppLF9hn6Lix8u6a/bcm564Bcu6qW2DOTVYn7y4nt27WnJus4X9vm8jafA02T85N1uhrsMZz7p6s2FhXzp2Ose4asHny7pp9DZabd/dVMXZHksNntg9Lct1sh+4+N8m5++j6k6uqS7t762rHsZl5DVaf12DF7TWXLrBPko2Vd/1bW31eg9XnNViy5eTWAxZwbJKNlXMT/97WAq/B6vMarLgVG+vKuaw0r8Hq28ivwb5apuCSJEdX1VFVdUCSk5Ns20fXAtioFpJLtyU5dfyk2eOSfKG7r586UIB1ZDm51RgXYOUY6wKb0j6ZGdvdN1fVE5O8Ncl+Sc7r7iv3xbUANqrd5dKqOnPcf06SC5KcmGR7khuTnL5a8QKsB8vJrca4ACvHWBfYrKp73mWuWKSqOmO8NYJV4jVYfV4DpuLf2urzGqw+rwFT8u9t9XkNVp/XgKn4t7b6vAarbyO/BoqxAAAAAAAT2FdrxgIAAAAAMGPTF2Or6rCqenNVfbSq/rmq/mRcPHxuv7tW1esWcL4LquqgJcbyjKr69aUcu5Gs5s+hqh5bVc9fjWuvF7ten6r6var6sd30eWxV3XXq2Fj75Ny1R85d2+RclkPOXXvk3LVP3mU55N21R95d2zZrzt3UxdiqqiRvSPKm7j46yfcluV2SZ87pt393X9fdj9zbObv7xO7+/L6IF9aS7v6d7v6bue1VtV+SxybZUMmS5ZNzYenkXBZLzoXlkXdZLHkXlm6z5dxNXYxN8uAkX+3ulyZJd389ya8m+c9V9YSq+ouq+sskb6uqI6vqg0lSVbepqtdW1RVV9ZqqendVbR33fbyq7jz2v6qq/rSqrqyqt1XVrcc+v1hVl1TV+6vq9VV1m9V5+mtDVZ06/izfX1V/Nmff91TVW6rqsqr6h6q6x9j+8PHn/r6q+puqusvY/oyqOq+q3l5VV1fVL82c6zFV9Z6quryq/vf4S52qOr2qPlJVf5/khyd86utGVf1mVX24qv4myd3HtpdV1SPHxx+vqt+pqncmOSXJ1iSvGn/WP1FVb5w510Or6g2r8TxYdXLuGiDnrn1yLitEzl0D5Nz1Qd5lhci7a4C8u/bJuYqx90py2WxDd38xyTVJ9k/yQ0lO6+4HzznuCUk+193fn+T3k/zAbs5/dJIXdPe9knw+yX8a29/Q3T/Y3fdJclWSx63Ac1mXqupeSX4zyYPHn8cvz+lybpIndfcPJPn1JC8c29+Z5Ljuvl+S85M8eeaYeyR5WJJjkzy9qm5RVfdM8rNJfri775vk60keXVWHJPndDEnyoUmOWflnub5V1Q8kOTnJ/ZL8xyQ/uJuuX+3uB3b3K5NcmuTR48/6giT3rKotY7/Tk7x030bNGiXnrjI5d+2Tc1lBcu4qk3PXB3mXFSTvrjJ5d+2Tcwf7r3YAq6yS9B7aL+zuz86z/4FJ/iRJuvuDVXXFbs7/se6+fHx8WZIjx8f3rqo/SHJQhtsW3rqU4DeIByd5XXd/Okm6+7NVlSSpqtsl+f+S/MWutiS3HL8fluQ1Y7I7IMnHZs75f7r7a0m+VlU3JLlLkodk+E/tkvFct05yQ5IHJHl7d+8cr/maDLeT8E3/Pskbu/vGJKmqbbvp95r5Gru7x3ckH1NVL80wCDl1n0TKWifnrj45d+2Tc1kpcu7qk3PXB3mXlSLvrj55d+2Tc6MYe2W++W5SkqSqbp/k8AzvbHxlN8fVbtrn+trM469n+AVNkpcleUR3v7+qHpvkQQs830a0u/+wkmHm9ufHdz/m+l9JntPd26rqQUmeMbNv7s99//E6L+/up37LxasesYfr800L+Rnt7vclGd6p+sskX03yF91984pExXoj564+OXd9kHNZCXLu6pNz1w95l5Ug764+eXd92PQ5d7MvU3BRkttU1anJNxYG/qMMyezGPRz3ziQ/Mx5zTJJ/t8jrHpjk+qq6RZJHL/LYjeaiJD9TVXdKkqq6464d4y0dH6uqR437qqruM+7+ziSfGB+ftsDrPLKqDt51naq6W5J3J3lQVd1pfD0etRJPaoN5R5KfrqpbV9WBSR6+gGO+lOHfeZKku69Lcl2S38rw+8XmJOeuPjl37ZNzWSly7uqTc9cHeZeVIu+uPnl37ZNzs8mLsd3dSX46yaOq6qNJPpKhsv60vRz6wiRbxtsHnpLkiiRfWMSlfzvDL+mFSf5psXFvJN19ZYZPl/z7qnp/kufM6fLoJI8b912Z5KSx/RkZbi/4hySfXsB1PpThF/Vt4+t2YZJDuvv68VzvSvI3Sd673Oe00XT3ezPcInB5ktcn+YcFHPayJOfUsMD2rndsX5Xk2vG1YBOSc1efnLv2ybmsFDl39cm564O8y0qRd1efvLv2ybmDGvIFizG+w3WL7v5qVX1PhndFvq+7b1rl0GDNqqrnJ3lfd79ktWNhfZFzYfHkXJZKzoWlkXdZKnkXFm+959zNvmbsUt0myd+N084ryeMlSti9qrosw5ovv7basbAuybmwCHIuyyTnwiLJuyyTvAuLsBFyrpmxAAAAAAAT2NRrxgIAAAAATEUxFgAAAABgAoqxAAAAAAATUIwFAAAAAJiAYiwAAAAAwAQUYwEAAAAAJvD/Aw1eEB/YLzmNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1728x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This block plots the following parameters for a vizualization of all three datasets:\n",
    "  1. Data Size\n",
    "  2. Accuracy Score of fitted model\n",
    "  3. Mean Squared Error of model\n",
    "  4. Coefficient of Determination\n",
    "\"\"\"\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_palette(sns.color_palette(\"Set2\"))\n",
    "fig,axes=plt.subplots(1,4,figsize=(24,6))\n",
    "sns.barplot(x=[\"Original\",\"cleaned\",\"dirty\"],y=[(original_training_size + original_testing_size),(cleaned_training_size + cleaned_testing_size),(dirty_training_size + dirty_testing_size)],ax=axes[0]).set(title='Data Size')\n",
    "sns.barplot(x=[\"Original\",\"cleaned\",\"dirty\"],y=[original_accuracy_score,cleaned_accuracy_score,dirty_accuracy_score],ax=axes[1]).set(title='Accuracy Score')\n",
    "sns.barplot(x=[\"Original\",\"cleaned\",\"dirty\"],y=[original_squared_error,cleaned_squared_error,dirty_squared_error],ax=axes[2]).set(title='Mean Squared Error')\n",
    "sns.barplot(x=[\"Original\",\"cleaned\",\"dirty\"],y=[original_dett_coeff,cleaned_dett_coeff,dirty_dett_coeff],ax=axes[3]).set(title='Coefficient of Determination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After Analyzing the performance on Data, the following conclusions can be reached:\n",
    "\n",
    "  1: The model performs perfectly on original dataset and yields highest prediction results.\n",
    "\n",
    "  2: The difficult part is deciding the working the provided dirty set and then again after cleaning that dataset. One thing to note here\n",
    "     is that although the model shows a slightly better performance on dirty dataset. In real world this is not acceptable as there\n",
    "     were many null values not accounted for in model and ignoring them resulted in a 33% loss from original dataset. So, for any application\n",
    "     a cleaner dataset with maximum possible trainign examples is preferred.\n",
    "    \n",
    "  3: Finally, the cleaned dataset resulted in a 93% accuracy in predictions compared to original dataset. This shows that the data was \n",
    "     cleaned quite properly and resulted more than 90% accuracy. In addition to that the mean-squared error is quite low, having a value of 0.07.\n",
    "     Now this compared to oriiginal can be interpreted as cleaned data having an almost perfect fit with exception to a few outliers.\n",
    "\n",
    "In Conclusion, the cleaning methods used were efficient, resulting in useful data that trained model with minimum abnormalities. The resulting \n",
    "model handled most predictions accurately as tested with the randomly separated testing data from input sample.\n",
    "\"\"\"\n",
    "print() # to give clear output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
